{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data_and_sort(path):\n",
    "    # print(path)\n",
    "    df = pd.read_csv(path)\n",
    "    # drop the suffix\n",
    "    df[\"utr\"] = df[\"utr\"].str[:50]\n",
    "    # reorder\n",
    "    df.drop(['Unnamed: 0'], axis=1, inplace=True)  # drop first column\n",
    "    if 'total_reads' in df:\n",
    "        df.sort_values(by=['total_reads'], inplace=True, ascending=False)\n",
    "    else:\n",
    "        df.sort_values(by=['total'], inplace=True, ascending=False)\n",
    "    df.reset_index(inplace=True, drop=True)  # necessary as sorting creates an extra index\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We begin by reading in all the raw data, sorting it and removing suffixes not part of the UTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ouga04b/ag_gagneur/home/karollus/.conda/envs/karollus-env/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3296: DtypeWarning: Columns (33,34,35,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['egfp_unmod_1', 'egfp_pseudo_2', 'egfp_m1pseudo_1', 'egfp_m1pseudo_2', 'mcherry_1', 'mcherry_2', 'designed_library', 'egfp_unmod_2', 'egfp_pseudo_1'])\n",
      "dict_keys(['egfp_unmod_1', 'mcherry_1', 'mcherry_2', 'designed_library', 'egfp_unmod_2'])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Read in all Data \"\"\"\n",
    "path = \"../Data/RawData/\"\n",
    "files = [os.path.join(path,file) for file in os.listdir(path) if file.startswith(\"GSM\")]\n",
    "df_list = {re.search(\"_(.*)\\.\",file).group(1):import_data_and_sort(file) for file in files}\n",
    "print(df_list.keys())\n",
    "# Remove the nonstandard chemistries\n",
    "entriesToRemove = ['egfp_pseudo_1', 'egfp_pseudo_2', 'egfp_m1pseudo_1', 'egfp_m1pseudo_2']\n",
    "for k in entriesToRemove:\n",
    "    df_list.pop(k, None)\n",
    "print(df_list.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We subset the data using the same cutoffs as in the sample code (except for the genetic algorithm data, where I impose a cutoff of minimum 200 reads (as I couldnt find which value is actually used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting the random mpra data\n",
    "keys = ['egfp_unmod_1', 'egfp_unmod_2', 'mcherry_1', 'mcherry_2']\n",
    "cuts = [280000, 300000, 180000, 170000]\n",
    "for key, cutoff in zip(keys, cuts):\n",
    "    df_list[key] = df_list[key].iloc[:cutoff].copy()\n",
    "\n",
    "# Subsetting the human data    \n",
    "human = df_list[\"designed_library\"][(df_list[\"designed_library\"]['library'] == 'human_utrs') | \n",
    "                                    (df_list[\"designed_library\"]['library'] == 'snv')]\n",
    "human = human.sort_values('total', ascending=False).reset_index(drop=True)\n",
    "human = human.iloc[:25000].copy()\n",
    "\n",
    "# Subsetting the genetic algorithm data\n",
    "GA_types = ['step_random_to_best_allow_uatg',\n",
    " 'step_random_to_best_no_uatgs',\n",
    " 'step_worst_to_best_allow_uatg',\n",
    " 'step_worst_to_best_no_uatg',\n",
    " 'target_allow_uaug_allow_stop',\n",
    " 'target_no_uaug_allow_stop',\n",
    " 'target_no_uaug_no_stop']\n",
    "GA = df_list['designed_library'][df_list['designed_library'][\"library\"].isin(GA_types)]\n",
    "GA = GA.iloc[:sum(GA[\"total\"] >= 200)].copy()\n",
    "\n",
    "df_list.pop(\"designed_library\", None)\n",
    "df_list[\"human\"] = human\n",
    "df_list[\"ga\"] = GA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We reduce to the needed columns (utr and rl) and add a library column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in df_list.items():\n",
    "    df = df.filter(regex=(\"rl|utr\"))\n",
    "    df[\"library\"] = key\n",
    "    df_list[key] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We prepare the test (20k), val (20k) and train (rest) split for all the sets except ga (only for training) and human (only for validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in df_list.items():\n",
    "    df[\"set\"] = \"\"\n",
    "    if key == \"human\":\n",
    "        df[\"set\"] = \"val\"\n",
    "    elif key == \"ga\":\n",
    "        df[\"set\"] = \"train\"\n",
    "    else:\n",
    "        df.loc[:20000, \"set\"] = \"test\"\n",
    "        df.loc[20000:40000, \"set\"] = \"val\"\n",
    "        df.loc[40000:, \"set\"] = \"train\"\n",
    "    df_list[key] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We combine the data into one large frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(df_list.values())    \n",
    "combined_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We collect the snv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_df = pd.read_csv(\"../Data/SNV/snv_phenotype_log_diff.csv\")\n",
    "snv_df.drop(['Unnamed: 0'], axis=1, inplace=True)  # drop first column\n",
    "snv_df = snv_df[snv_df['obs_diff'] != 0.0]\n",
    "snv_df = snv_df[snv_df['total'] >= 620]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We collect the PTR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ouga04b/ag_gagneur/home/karollus/.conda/envs/karollus-env/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: 'select' is deprecated and will be removed in a future release. You can use .loc[labels.map(crit)] as a replacement\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# We get the PTR data\n",
    "ptr_df = pd.read_csv(\"../Data/PTR/ptr.tsv\", sep='\\t')\n",
    "# We average over all tissues\n",
    "ptr_vals = ptr_df.select(lambda col: col.endswith('PTR'), axis=1).apply(pd.to_numeric, errors='coerce').mean(axis=1)\n",
    "ptr_vals_df = pd.DataFrame({\"GeneName\":ptr_df[\"GeneName\"], \"PTR\":ptr_vals})\n",
    "\n",
    "# We get the sequences\n",
    "seq_df = pd.read_csv(\"../Data/PTR/seq.tsv\", sep='\\t')\n",
    "\n",
    "# We combine\n",
    "combined_df_ptr = seq_df[[\"GeneName\",\"UTR5_Sequence\"]].merge(ptr_vals_df)\n",
    "combined_df_ptr = combined_df_ptr.rename(index=str, columns={\"UTR5_Sequence\": \"utr\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all the data in a dict and pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\"data\":combined_df, \"snv\":snv_df, \"ptr\":combined_df_ptr}\n",
    "with open(\"../Data/data_dict.pkl\", 'wb') as handle:\n",
    "    pickle.dump(data_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
