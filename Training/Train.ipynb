{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import re\n",
    "import random\n",
    "random.seed(1337)\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import model\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bivar(evaluation_egfp, evaluation_mcherry):\n",
    "    c1 = (0.3, 0.45, 0.69)\n",
    "    c2 = 'r'\n",
    "    g = sns.JointGrid(x='predicted', y=\"actual\", data=evaluation_egfp, space=0, xlim=(0,10), ylim=(0,10), ratio=6, size=7)\n",
    "    g.plot_joint(plt.scatter,s=20, color=c1, linewidth=0.2, alpha='0.5', edgecolor='white')\n",
    "    g.x = evaluation_mcherry['predicted'].values\n",
    "    g.y = evaluation_mcherry['actual'].values\n",
    "    g.plot_joint(plt.scatter, s=20, linewidth=0.2, alpha='0.5', color=c2, edgecolor='white')\n",
    "    f = g.fig\n",
    "    ax = f.gca()\n",
    "    x = np.linspace(*ax.get_xlim())\n",
    "    plt.plot(x, x)\n",
    " \n",
    "\"\"\" VALIDATIONS \"\"\"\n",
    "    \n",
    "def prepare_ptr_data(df, seq_pad=0):\n",
    "    data_dict = {}\n",
    "    data_dict[\"input\"] = utils.encode_fromdf(df, 0, seq_pad=seq_pad, variable_len=True)\n",
    "    return data_dict\n",
    "    \n",
    "def get_ptr_corr(model, data, df):\n",
    "    inputs = [data[\"input\"][\"seq\"], data[\"input\"][\"indicator\"]]\n",
    "    predictions = model.predict(inputs)\n",
    "    print(stats.pearsonr(df[\"PTR\"],predictions.reshape(-1)))\n",
    "    \n",
    "def prepare_data(df, col, seq_pad=0):\n",
    "    data_dict = {}\n",
    "    data_dict[\"input\"] = utils.encode_fromdf(df, 2, col=col, seq_pad=seq_pad)\n",
    "    data_dict[\"output\"] = np.array(df[\"hrl\"]).reshape(-1,1)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/data_dict.pkl\", 'rb') as handle:\n",
    "    data_dict = pickle.load(handle)\n",
    "\n",
    "data_df = data_dict[\"data\"]\n",
    "snv_df = data_dict[\"snv\"]\n",
    "ptr_df = data_dict[\"ptr\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the data in the required input format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = {}\n",
    "for set_type in data_df[\"set\"].unique():\n",
    "    df_slice = data_df[data_df[\"set\"] == set_type]\n",
    "    set_type_dict = {}\n",
    "    for library in df_slice[\"library\"].unique():\n",
    "        set_type_dict[library] = utils.encode_df(df_slice[df_slice[\"library\"] == library])  \n",
    "    encoded_data[set_type] = set_type_dict\n",
    "\n",
    "snv_encoded = {}\n",
    "snv_df[\"library\"] = \"human\"\n",
    "snv_encoded[\"snv\"] = utils.encode_df(snv_df, col=\"utr\", output_col=\"hrl\")\n",
    "snv_encoded[\"wt\"] = utils.encode_df(snv_df, col=\"mother\", output_col=\"hrl\")\n",
    "sub = snv_df\n",
    "path_list = ['Pathogenic', 'Likely pathogenic', 'Pathogenic, other', 'Pathogenic/Likely pathogenic']\n",
    "benign_list = ['Benign/Likely benign', 'Benign', 'Likely Benign']\n",
    "uncertain_list = ['Conflicting interpretations of pathogenicity', 'Uncertain significance']\n",
    "path = sub[(sub['clin_sig'] == path_list[0]) | (sub['clin_sig'] == path_list[1]) |\n",
    "           (sub['clin_sig'] == path_list[2]) | (sub['clin_sig'] == path_list[3])]\n",
    "non = sub[(sub['clin_sig'] == benign_list[0]) | (sub['clin_sig'] == benign_list[1]) | (sub['clin_sig'] == benign_list[2])]\n",
    "unsure = sub[(sub['clin_sig'] == uncertain_list[0]) | (sub['clin_sig'] == uncertain_list[1])]\n",
    "\n",
    "ptr_df[\"library\"] = \"egfp_unmod_1\"\n",
    "ptr_encoded = utils.encode_df(ptr_df, col=\"utr\", output_col=None, variable_len=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate a basic model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '/data/ouga04b/ag_gagneur/home/karollus/5UTRModel/Collab/Training/model.py'>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "utr_model = model.create_model_masked_bordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      "240000/240000 [==============================] - 24s 102us/step - loss: 0.3122 - val_loss: 0.2791\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.27912, saving model to basic_model.h5\n",
      "Epoch 2/10\n",
      "240000/240000 [==============================] - 25s 105us/step - loss: 0.3027 - val_loss: 0.2665\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.27912 to 0.26651, saving model to basic_model.h5\n",
      "Epoch 3/10\n",
      "240000/240000 [==============================] - 25s 104us/step - loss: 0.2964 - val_loss: 0.2941\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26651\n",
      "Epoch 4/10\n",
      "240000/240000 [==============================] - 26s 106us/step - loss: 0.2889 - val_loss: 0.2927\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26651\n",
      "Epoch 5/10\n",
      "240000/240000 [==============================] - 26s 106us/step - loss: 0.2828 - val_loss: 0.2831\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26651\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "utils.train(utr_model, encoded_data, libraries=[\"egfp_unmod_1\"], epochs=10, file=\"basic_model.h5\")\n",
    "utr_model = load_model(\"basic_model.h5\", custom_objects={'FrameSliceLayer': model.FrameSliceLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsquared on set egfp_unmod_1 : 0.9184789401533968, Pearson: 0.9210255977813298\n"
     ]
    }
   ],
   "source": [
    "pred = utils.evaluate(utr_model, encoded_data, libraries=[\"egfp_unmod_1\"], do_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "820244/820244 [==============================] - 41s 50us/step - loss: 3.3107\n",
      "Epoch 2/2\n",
      "820244/820244 [==============================] - 39s 48us/step - loss: 0.3212\n"
     ]
    }
   ],
   "source": [
    "utr_model = utils.retrain_only_scaling(utr_model, encoded_data, batch_size=128, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsquared on set egfp_unmod_1 : 0.909004145542096, Pearson: 0.9099067587126427\n",
      "Rsquared on set mcherry_1 : 0.7279082654301345, Pearson: 0.7280978897307177\n",
      "Rsquared on set mcherry_2 : 0.7635886128590488, Pearson: 0.7652201512338017\n",
      "Rsquared on set egfp_unmod_2 : 0.856273726593918, Pearson: 0.8579424133934646\n",
      "Rsquared on set human : 0.7617980195718617, Pearson: 0.7619559824295236\n"
     ]
    }
   ],
   "source": [
    "utils.evaluate(utr_model, encoded_data, libraries=['mcherry_1', 'mcherry_2', 'egfp_unmod_2', 'human'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on the test set, human data, snv data and ptr data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['egfp_unmod_1', 'mcherry_1', 'mcherry_2', 'egfp_unmod_2', 'human', 'ga']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_df[\"library\"].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
